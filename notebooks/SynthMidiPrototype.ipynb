{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mido\n",
    "from mido import MidiFile, MidiTrack, Message, MetaMessage, bpm2tempo\n",
    "from musicnet.utils import notes_vocab, Track, get_train_ids, SyntheticTrack, PROJECT_ROOT_DIR, find_lr, create_vocab\n",
    "from musicnet.preprocessing.wav_specs_and_notes.utils import Preprocessor\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import os\n",
    "from musicnet.params import config\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIDI_OUT_DIR = os.path.join(PROJECT_ROOT_DIR, \"data\", \"preprocessed\", \"synth_midi\", \"midi\")\n",
    "WAV_OUT_DIR = os.path.join(PROJECT_ROOT_DIR, \"data\", \"preprocessed\", \"synth_midi\", \"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(MIDI_OUT_DIR, 0o775, exist_ok=True)\n",
    "os.makedirs(WAV_OUT_DIR, 0o775, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tps=100\n",
    "min_note_ticks=1\n",
    "max_note_ticks=100\n",
    "max_silmultaneous_notes=5\n",
    "sidechannel_sparsity=2\n",
    "notes=list(range(20, 106))\n",
    "# \"Assisting\" notes will be chosen from standard distribution with the mean at the main note\n",
    "# and the standard distribution specified\n",
    "notes_std=20\n",
    "track_length_per_note=7200\n",
    "velocity_min=32\n",
    "velocity_max=96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 3))\n",
    "# ax = plt.gca()\n",
    "ax = None\n",
    "examples = [notes[3], notes[len(notes)//2], notes[-3]]\n",
    "for i, main_note in enumerate(examples):\n",
    "    ax = plt.subplot(1, len(examples), i+1, sharey=ax)\n",
    "    plt.title(f\"main_note={main_note}\")\n",
    "    probabilities = np.array([scipy.stats.norm.pdf(n, loc=main_note, scale=notes_std) if n != main_note else 0 for n in notes])\n",
    "    probabilities = probabilities / probabilities.sum() # Rescale so that the probabilities sum to 1\n",
    "    plt.plot(notes, probabilities, \"o\", ms=3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_ticks = tps * track_length_per_note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AccompanyingNotesGenerator:\n",
    "    def __init__(self, main_note, batch_size=10000) -> None:\n",
    "        self.main_note = main_note\n",
    "        self.batch_size = batch_size\n",
    "        self.batch = []\n",
    "        p = np.array([scipy.stats.norm.pdf(n, loc=main_note, scale=notes_std) if n != main_note else 0 for n in notes])\n",
    "        p = p / p.sum()\n",
    "        self.p = p\n",
    "    \n",
    "    def next(self):\n",
    "        if len(self.batch) == 0:\n",
    "            self.batch = list(np.random.choice(notes, size=self.batch_size, p=self.p))\n",
    "        return self.batch.pop()\n",
    "\n",
    "def generate_channel_events(main_note, is_sidechannel=False, channel=0, program=0, sparsity=1):\n",
    "    tick = 0\n",
    "    events = [{ \"tick\": 0, \"type\": \"program_change\", \"channel\": channel, \"program\": program }]\n",
    "    is_note_on = True\n",
    "    generator = AccompanyingNotesGenerator(main_note)\n",
    "    while tick < total_ticks:\n",
    "        event = {\n",
    "            \"tick\": tick,\n",
    "            \"channel\": channel\n",
    "        }\n",
    "        if is_note_on:\n",
    "            event[\"type\"] = \"note_on\"\n",
    "            event[\"velocity\"] = random.randint(velocity_min, velocity_max)\n",
    "            note = generator.next() if is_sidechannel else main_note\n",
    "            event[\"note\"] = note\n",
    "        else:\n",
    "            event[\"type\"] = \"note_off\"\n",
    "            event[\"note\"] = note\n",
    "        events.append(event)\n",
    "        is_note_on = not is_note_on\n",
    "        tick_delta = random.randint(min_note_ticks, max_note_ticks)\n",
    "        if is_note_on:\n",
    "            tick_delta *= sparsity\n",
    "        tick += tick_delta\n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = []\n",
    "for note in notes[:1]:\n",
    "    # Main channel events\n",
    "    events = events + generate_channel_events(main_note=note, is_sidechannel=False, channel=0, sparsity=1)\n",
    "    # \"Side\" channels events\n",
    "    for c in range(1, max_silmultaneous_notes):\n",
    "        events = events + generate_channel_events(main_note=note, is_sidechannel=True, channel=c, sparsity=sidechannel_sparsity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = pd.DataFrame(events).sort_values(by=[\"tick\", \"type\"], ascending=[True, False]).reset_index(drop=True)\n",
    "events[\"time\"] = (events[\"tick\"] - events[\"tick\"].shift(1).fillna(0)).astype(int)\n",
    "events[\"velocity\"] = events[\"velocity\"].astype(pd.Int8Dtype())\n",
    "events[\"program\"] = events[\"program\"].astype(pd.Int8Dtype())\n",
    "events[\"note\"] = events[\"note\"].astype(pd.Int8Dtype())\n",
    "events = events.drop(columns=[\"tick\"])\n",
    "display(events[:10])\n",
    "note_messages = [ Message(**{ k : v for k, v in event.items() if pd.notnull(v) }) for event in events.to_dict(\"records\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_id = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = MidiFile(ticks_per_beat=tps)\n",
    "# Set tempo to 60 bpm, so 1 beat / second to simplify calculations\n",
    "messages = [MetaMessage(\"set_tempo\", tempo=bpm2tempo(60), time=0)]\n",
    "messages += note_messages\n",
    "track = MidiTrack(messages)\n",
    "file.tracks.append(track)\n",
    "midi_path = os.path.join(MIDI_OUT_DIR, f\"{track_id}.midi\")\n",
    "file.save(midi_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# track = Track(get_train_ids()[-1])\n",
    "# file = mido.MidiFile(track.get_midi_path())\n",
    "# messages = list(file)\n",
    "\n",
    "# messages[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_path = os.path.join(WAV_OUT_DIR, f\"{track_id}.wav\")\n",
    "subprocess.run(\n",
    "    f\"fluidsynth -F {wav_path} /usr/share/sounds/sf2/default-GM.sf2 {midi_path}\",\n",
    "    shell=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track = SyntheticTrack(track_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track.get_notes()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playing_notes = np.ones([total_ticks, max_silmultaneous_notes, 5]) * -1\n",
    "for note in track.get_notes().to_dict(\"records\"):\n",
    "    s = int(note[\"start\"] * 100)\n",
    "    e = int(note[\"end\"] * 100)\n",
    "    duration = e - s\n",
    "    playing_notes[s : e, note[\"channel\"]] = np.concatenate([\n",
    "        [[note[\"note\"]]] * duration,\n",
    "        [[note[\"velocity\"]]] * duration,\n",
    "        [[duration]] * duration,\n",
    "        np.arange(1, duration+1).reshape(-1, 1),\n",
    "        np.arange(duration-1, -1, -1).reshape(-1, 1)\n",
    "    ], axis=1)\n",
    "playing_notes_df = pd.DataFrame({\n",
    "    **{ f\"note_{c}\": playing_notes[:, c, 0] for c in range(0, max_silmultaneous_notes) },\n",
    "    **{ f\"velocity_{c}\": playing_notes[:, c, 1] for c in range(0, max_silmultaneous_notes) },\n",
    "    **{ f\"duration_{c}\": playing_notes[:, c, 2] for c in range(0, max_silmultaneous_notes) },\n",
    "    **{ f\"playing_{c}\": playing_notes[:, c, 3] for c in range(0, max_silmultaneous_notes) },\n",
    "    **{ f\"remaining_{c}\": playing_notes[:, c, 4] for c in range(0, max_silmultaneous_notes) },\n",
    "})\n",
    "playing_notes_df = playing_notes_df.replace(-1.0, None)\n",
    "# silmultaneously_playing_notes = (playing_notes[:, :, 0] > -1).sum(axis=1)\n",
    "# main_note_velocity = playing_notes[:, 0, 1] * (playing_notes[:, 0, 1] > 0)\n",
    "# other_notes_mean_velocity = np.array(list(map(lambda pn: pn[pn > -1].mean() if pn.max() > -1 else 0, playing_notes[:, 1:, 1])))\n",
    "# print(playing_notes.shape, silmultaneously_playing_notes.shape, main_note_velocity.shape, other_notes_mean_velocity.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playing_notes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['dataset']['wav_source'][\"type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hop_length = 110\n",
    "target_sr = 44000\n",
    "note_rounding = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = Preprocessor(\n",
    "    chunk_size_sec=3600,\n",
    "    chunk_shift_sec=3600,\n",
    "    notes_vocab=create_vocab(notes),\n",
    "    target_sr=target_sr,\n",
    "    note_rounding=note_rounding,\n",
    "    spectogram={\n",
    "        \"n_fft\": 2200, # 50 ms\n",
    "        \"hop_length\": hop_length, # 5 ms\n",
    "        \"min_hz\": 0,\n",
    "        \"n_filters\": 200,\n",
    "        \"unit\": \"decibels\",\n",
    "    }\n",
    ") # Preprocessor(chunk_size_sec=60, chunk_shift_sec=60, target_sr=44000, spectogram=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_x, o_y = preprocessor.preprocess(track)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only use 1st chunk (1st hour) of data to avoid memory overflow etc.\n",
    "o_x = o_x[:1]\n",
    "o_y = o_y[:1]\n",
    "print(o_x.shape)\n",
    "print(o_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(range(0, 11))[5:-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_idx = 0\n",
    "y_padding = 1\n",
    "shift_x = int(note_rounding / (hop_length / target_sr))\n",
    "size_x = shift_x * (2 * y_padding + 1)\n",
    "print(size_x, shift_x)\n",
    "\n",
    "y = o_y.reshape(-1, o_y.shape[-1])\n",
    "y = np.array(list(map(lambda v: v[note_idx] == True, y)))\n",
    "y = y[y_padding:-y_padding]\n",
    "x = o_x.reshape(-1, o_x.shape[-1])\n",
    "x = np.array([x[i : i  + size_x].reshape(-1) for i in range(0, len(x) - size_x, shift_x)])\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_idx = int(len(x)*0.8)\n",
    "x_train = x[:split_idx]\n",
    "y_train = y[:split_idx]\n",
    "x_val = x[split_idx:]\n",
    "y_val = y[split_idx:]\n",
    "print(x_train.shape, y_train.shape, x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler((-1, 1))\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_val = scaler.transform(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score\n",
    "from time import time\n",
    "\n",
    "\n",
    "models = [\n",
    "    RandomForestClassifier(n_jobs=8),\n",
    "    ExtraTreesClassifier(n_jobs=8),\n",
    "    # LinearSVC(),\n",
    "    # KNeighborsClassifier(n_jobs=8),\n",
    "    LogisticRegression(n_jobs=8, max_iter=1000)\n",
    "    # TODO: Gradient Boosting Classifier\n",
    "]\n",
    "\n",
    "metrics = [precision_score, recall_score, f1_score, accuracy_score]\n",
    "\n",
    "results = []\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    print(f\"Training {model_name}...\")\n",
    "    s = time()\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_val)\n",
    "    metric_values = { metric.__name__: round(metric(y_val, y_pred), 5) for metric in metrics }\n",
    "    print(metric_values)\n",
    "    results.append({\n",
    "        \"model\": model_name,\n",
    "        **metric_values\n",
    "    })\n",
    "    print(f\"Took: {time()-s}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For comparison we'll try a simple CNN which will treat samples of x as 2-dimensional inputs\n",
    "n_filters = config[\"dataset\"][\"preprocessor\"][\"params\"][\"spectogram\"][\"n_filters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN architecture where spectogram is 2d with 1 channel\n",
    "def build_cnn1(optimizer=keras.optimizers.Adam()):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Input(shape=(n_filters, 5, 1)))\n",
    "    model.add(keras.layers.Conv2D(20, kernel_size=(3, 3), padding=\"same\", activation=\"gelu\"))\n",
    "    model.add(keras.layers.MaxPooling2D((3, 1)))\n",
    "    model.add(keras.layers.Conv2D(40, kernel_size=(3, 3), padding=\"same\", activation=\"gelu\"))\n",
    "    model.add(keras.layers.MaxPooling2D((3, 1)))\n",
    "    model.add(keras.layers.Conv2D(80, kernel_size=(3, 3), padding=\"same\", activation=\"gelu\"))\n",
    "    model.add(keras.layers.MaxPooling2D((3, 1)))\n",
    "    model.add(keras.layers.Conv2D(160, kernel_size=(3, 3), padding=\"same\", activation=\"gelu\"))\n",
    "    model.add(keras.layers.GlobalMaxPooling2D())\n",
    "    model.add(keras.layers.Dropout(0.1))\n",
    "    model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(),\n",
    "        loss=keras.losses.BinaryCrossentropy(),\n",
    "        metrics=[\n",
    "            keras.metrics.Precision(0.5),\n",
    "            keras.metrics.Recall(0.5),\n",
    "            keras.metrics.BinaryAccuracy()\n",
    "        ]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# CNN architecture where spectogram is 1d with n_filters channels (no pooling)\n",
    "def build_cnn2(optimizer=keras.optimizers.Adam()):\n",
    "    inputs = keras.layers.Input(shape=(size_x, n_filters))\n",
    "    x = inputs\n",
    "    x_skip = inputs\n",
    "    residual_blocks = 3\n",
    "    for _ in range(0, residual_blocks):\n",
    "        x = keras.layers.SeparableConv1D(200, kernel_size=3, padding=\"same\", activation=\"gelu\")(x)\n",
    "        x = keras.layers.SeparableConv1D(200, kernel_size=3, padding=\"same\", activation=None)(x)\n",
    "        x = keras.layers.Add()([x, x_skip])\n",
    "        x = keras.layers.Activation(\"gelu\")(x)\n",
    "        x_skip = x\n",
    "    x = keras.layers.GlobalMaxPooling1D()(x)\n",
    "    x = keras.layers.Dropout(0.1)(x)\n",
    "    x = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=x)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(),\n",
    "        loss=keras.losses.BinaryCrossentropy(),\n",
    "        metrics=[\n",
    "            keras.metrics.Precision(0.5),\n",
    "            keras.metrics.Recall(0.5),\n",
    "            keras.metrics.BinaryAccuracy()\n",
    "        ]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# CNN architecture that will work with raw wav data as input (the shape is gonna be (4096, 1) and will represent 100ms)\n",
    "def build_ccn3(optimizer=keras.optimizers.Adam()):\n",
    "    inputs = keras.layers.Input(shape=(2200, 1))\n",
    "    x = inputs\n",
    "    x_skip = None\n",
    "    for dl in [2, 4, 8, 16, 32]:\n",
    "        x = keras.layers.Conv1D(\n",
    "            filters=50,\n",
    "            kernel_size=2,\n",
    "            padding=\"same\",\n",
    "            activation=None,\n",
    "            dilation_rate=dl\n",
    "        )(x)\n",
    "        if x_skip is None:\n",
    "            x = keras.layers.Activation(\"gelu\")(x)\n",
    "            x_skip = x\n",
    "        else:\n",
    "            x = keras.layers.Add()([x, x_skip])\n",
    "            x = keras.layers.Activation(\"gelu\")(x)\n",
    "            x_skip = x\n",
    "    x = keras.layers.MaxPool1D(22)(x)\n",
    "    x_skip = None\n",
    "    for dl in [2, 4, 8, 16]:\n",
    "        x = keras.layers.Conv1D(\n",
    "            filters=100,\n",
    "            kernel_size=2,\n",
    "            padding=\"same\",\n",
    "            activation=None,\n",
    "            dilation_rate=dl\n",
    "        )(x)\n",
    "        if x_skip is None:\n",
    "            x = keras.layers.Activation(\"gelu\")(x)\n",
    "            x_skip = x\n",
    "        else:\n",
    "            x = keras.layers.Add()([x, x_skip])\n",
    "            x = keras.layers.Activation(\"gelu\")(x)\n",
    "            x_skip = x\n",
    "    x = keras.layers.MaxPool1D(10)(x)\n",
    "    x_skip = None\n",
    "    for dl in [2, 4, 8]:\n",
    "        x = keras.layers.Conv1D(\n",
    "            filters=200,\n",
    "            kernel_size=2,\n",
    "            padding=\"same\",\n",
    "            activation=None,\n",
    "            dilation_rate=dl\n",
    "        )(x)\n",
    "        if x_skip is None:\n",
    "            x = keras.layers.Activation(\"gelu\")(x)\n",
    "            x_skip = x\n",
    "        else:\n",
    "            x = keras.layers.Add()([x, x_skip])\n",
    "            x = keras.layers.Activation(\"gelu\")(x)\n",
    "            x_skip = x\n",
    "    x = keras.layers.GlobalMaxPooling1D()(x)\n",
    "    x = keras.layers.Dropout(0.5)(x)\n",
    "    x = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=x)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(),\n",
    "        loss=keras.losses.BinaryCrossentropy(),\n",
    "        metrics=[\n",
    "            keras.metrics.Precision(0.5),\n",
    "            keras.metrics.Recall(0.5),\n",
    "            keras.metrics.BinaryAccuracy()\n",
    "        ]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1, n_filters, 5, 1)\n",
    "x_val = x_val.reshape(-1, n_filters, 5, 1)\n",
    "model1 = build_cnn1()\n",
    "model1.fit(x_train, y_train, epochs=10, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1, size_x, n_filters)\n",
    "x_val = x_val.reshape(-1, size_x, n_filters)\n",
    "# model2, _, init_epoch = find_lr(build_cnn2, x_train, y_train)\n",
    "model2 = build_cnn2(keras.optimizers.Adam(0.001))\n",
    "model2.fit(x_train, y_train, epochs=10, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = build_ccn3()\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = build_ccn3(keras.optimizers.Adam(0.0001))\n",
    "init_epoch = 0\n",
    "# model3, _, init_epoch = find_lr(build_ccn3, x_train, y_train)\n",
    "model3.fit(x_train, y_train, initial_epoch=init_epoch, epochs=10, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Things to test:\n",
    "# - Models working on raw wav data (no spectogram): Doesn't seem like the really do better\n",
    "# - Models working on different kinds of spectograms (lower hop size, higher kernels etc.)\n",
    "# - Models working on less than 30 minutes of data\n",
    "\n",
    "# TODO: Optimalizations:\n",
    "# - Make the CNN work on multiple samples at once (just like in the MusicNet example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_notes_data = playing_notes_df.iloc[center_y:-center_y+1][split_idx:]\n",
    "val_notes_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misses = ((y_pred > 0.5) != y_val.reshape(-1, 1))\n",
    "print(misses.shape)\n",
    "print(misses.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misses_data = val_notes_data.iloc[misses]\n",
    "misses_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[note_cols[1:]].stack().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subplot_size = (6, 1)\n",
    "\n",
    "note_cols = [f\"note_{i}\" for i in range(0, max_silmultaneous_notes)]\n",
    "velocity_cols = [f\"velocity_{i}\" for i in range(0, max_silmultaneous_notes)]\n",
    "\n",
    "def plot_comparison(title, func, bins=30):\n",
    "    plt.title(title)\n",
    "    plt.hist(func(val_notes_data), bins=bins, label=\"All\", alpha=0.5, color=\"blue\")\n",
    "    plt.hist(func(misses_data), bins=bins, label=\"Failed\", alpha=0.5, color=\"red\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(*subplot_size, 1)\n",
    "plot_comparison(\"Note 0 playing\", lambda df: ~df[\"note_0\"].isna() * 1, bins=2)\n",
    "\n",
    "plt.subplot(*subplot_size, 2)\n",
    "plt.title(\"Note 0 velocity\")\n",
    "plot_comparison(\"Note 0 velocity\", lambda df: df[\"velocity_0\"].dropna())\n",
    "\n",
    "plt.subplot(*subplot_size, 3)\n",
    "plt.title(\"Note 0 duration\")\n",
    "plot_comparison(\"Note 0 duration\", lambda df: df[\"duration_0\"].dropna())\n",
    "\n",
    "plt.subplot(*subplot_size, 4)\n",
    "plot_comparison(\"Other note values\", lambda df: df[note_cols[1:]].stack().values)\n",
    "\n",
    "plt.subplot(*subplot_size, 5)\n",
    "plot_comparison(\"Other notes velocity\", lambda df: df[velocity_cols[1:]].stack().values)\n",
    "\n",
    "plt.subplot(*subplot_size, 6)\n",
    "plot_comparison(\"Notes playing silmultaneously\", lambda df: (~df[note_cols].isna()).sum(axis=1))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
